# Alacard â€” Supabase Sprint (3â€‘Hour Demo PRD)

This is a timeâ€‘boxed plan to ship a working demo today using Supabase for persistence and a Figma Make prototype for flows. It trims scope to a single, reliable path and defines concrete deliverables we can show live at the end of the sprint.

## Objective (Done = Demoable Endâ€‘toâ€‘End)

- Live Arena demo (card deck): pick from visual cards for models and prompts, run a headâ€‘toâ€‘head chat on 3 preset prompts, show outputs sideâ€‘byâ€‘side, choose a winner, and save a shareable link.
- Supabase persistence: store the match and results; share page reads from Supabase by `share_id`.
- â€œRun as Notebookâ€ button: generates and downloads a runnable `.ipynb` that pulls the latest samples from Hugging Face for the selected HF model (README snippets or widget examples) and includes a verified hello cell.
- Figma prototype: clickâ€‘through of the broader experience (Arena setup â†’ streaming â†’ decision â†’ share â†’ notebook), matching the live demo UI.
- Remixable recipes: users can click â€œRemixâ€ on any share page to open the Arena preâ€‘filled with the same card deck (models + prompts), tweak a card, and generate a new share link.

Nonâ€‘goals for the sprint

- No agentic multiâ€‘step notebook synthesis; we do direct templating using HF sources.
- No complex multiâ€‘task support; textâ€‘generation/textâ€‘toâ€‘text only.
- No auth/RLS; if needed, simple anon writes with a service key on server only.

## Demo Script (What we will show)

1) Open Figma and narrate the flow (60â€“90s), highlighting the visual card deck: Model Cards on the left, Prompt Cards on the right, and a Recipe Bar summarizing the selection.
2) Open the live Arena page, choose two Model Cards (e.g., `openai:gpt-4o-mini` vs `openai:gpt-4o`) and a Prompt Card pack of 3. Run, watch outputs populate sideâ€‘byâ€‘side with small perâ€‘card badges (latency, token count).
3) Pick winner and see a score. Copy share link, open it in a fresh tab and see static results including the recipe summary. Click â€œRemixâ€ to open Arena with the same cards preâ€‘selected; swap a Model Card and reâ€‘run.
4) Click â€œRun as Notebookâ€ â†’ download `.ipynb` â†’ open locally (Jupyter/VS Code) â†’ run env cell + hello cell.

## Thin Architecture (Today)

- Frontend: singleâ€‘page Arena + Share using Next.js/React.
- API routes: serverâ€‘side calls OpenAI and/or HF Inference API; returns outputs (batch or SSE if time).
- Supabase: one table for matches with JSON payloads to avoid joins. Store the selected recipe (card choices) inside `meta.recipe`.
- Notebook generator: server endpoint that fetches latest HF samples (README and/or widget examples) and injects them into a `.ipynb` template; verifies a hello cell locally by simulating a minimal call (string presence or dry run) before returning.

## Minimal Supabase Schema (SQL)

Use a single table to reduce complexity; store prompts/outputs as JSON.

```sql
create extension if not exists pgcrypto;

create table if not exists public.matches (
  id uuid primary key default gen_random_uuid(),
  created_at timestamptz not null default now(),
  share_id text unique not null,
  model_a text not null,
  model_b text not null,
  system_prompt text,
  prompts jsonb not null,
  outputs jsonb,           -- { items: [{prompt, a, b, a_ms, b_ms}] }
  scoring jsonb,           -- { winner: 'A'|'B'|'tie', votes: {...}, rubric: {...} }
  meta jsonb               -- { client_version, notes, recipe: { models: [model_a, model_b], prompts: [p1,p2,p3], title, emoji } }
);

create index if not exists matches_share_idx on public.matches(share_id);
```

RLS: disabled for sprint. Only server writes using service key.

## Endpoints (Shape only)

- `POST /api/match` â†’ create + run
  - body: `{ model_a, model_b, system_prompt, prompts: [string] }`
  - returns: `{ share_id, outputs: [{prompt, a, b, a_ms, b_ms}] }`

- `POST /api/match/:share_id/score` â†’ store winner
  - body: `{ winner: 'A'|'B'|'tie', votes?: {...}, rubric?: {...} }`
  - returns: `{ ok: true }`

- `GET /api/match/:share_id` â†’ fetch
  - returns: full `match` row JSON

- Remix behavior (clientâ€‘side): Share page has a â€œRemixâ€ button that opens `/arena?from={share_id}`. The Arena reads `meta.recipe` from the fetched match JSON and preâ€‘selects the same Model and Prompt Cards.

- `GET /api/notebook?hf_model={org/name}&task=chat&share_id=...` â†’ download `.ipynb`
  - Behavior: fetch HF model metadata and README; extract first suitable Python snippet or widget text sample; fall back to generic snippet based on `pipeline_tag`.
  - returns: runnable notebook with env setup, HF sample section, and a hello cell. If `share_id` provided, include a markdown cell describing the recipe used (model selection and prompt set) for traceability.

## Env Vars

- `NEXT_PUBLIC_SUPABASE_URL`
- `SUPABASE_SERVICE_ROLE_KEY` (server only)
- `OPENAI_API_KEY`
- `HF_API_TOKEN` (for HF Inference API and rateâ€‘limit friendly README fetch if required)

## Presets (Hardcoded for Speed)

- Arena models (Model Cards): `openai:gpt-4o-mini` vs `hf:meta-llama/Llama-3.1-8B-Instruct` via HF Inference API (or swap to another stable instruct model).
- Notebook target model: default to the selected HF model for notebook generation.
- System prompt: â€œHelpful assistant; answer concisely.â€
- Prompt Cards (3â€‘pack):
  1. â€œExplain RAG in one paragraph for a product manager.â€
  2. â€œWrite a JSON schema for a blog post with title, body, tags.â€
  3. â€œList 5 risks of LLM evaluations and a quick mitigation for each.â€

Recipe starters (visual + fun):
- â€œSpeed vs Smartsâ€ âš¡ğŸ§ : `gpt-4o-mini` vs `Llamaâ€‘3.1â€‘8Bâ€‘Instruct`, above 3 prompts.
- â€œStructured Output Showdownâ€ ğŸ§©: same models; replace prompt #2 with â€œReturn JSON with keys title, tags, summary.â€
- â€œSecurity Lensâ€ ğŸ›¡ï¸: swap prompt #3 with â€œName 5 promptâ€‘injection vectors + mitigations.â€

## Notebook Template (Runnable, HFâ€‘Sourced)

Cells (generated serverâ€‘side):
- Markdown title: â€œAlacard | {hf_model_id} Quickstartâ€ with model license + link to HF card.
- Code: env setup; installs `transformers`, `huggingface_hub` (and `requests` if using Inference API).
- Code (hello cell): minimal call using HF Inference API or `transformers` pipeline chosen by `pipeline_tag` (textâ€‘generation/text2text).
- Markdown: â€œSamples from Model Cardâ€ with the first extracted example prompt/code.
- Code: runnable sample adapted from README/widget (sanitized for keys/paths).
- Markdown: â€œRecipe usedâ€ showing selected models and prompts (if `share_id` set).
- Markdown: next steps + link back to share page.

Sourcing logic (order):
1) GET `https://huggingface.co/api/models/{hf_model_id}` to read `pipeline_tag`, `tags`, and commit SHA.
2) Fetch README at the latest commit (`.../resolve/{sha}/README.md`); extract the first Python fenced block; if none, extract the first codeâ€‘fenced text prompt.
3) If README lacks examples, fallback to a generic snippet based on `pipeline_tag`.
4) Inject model id and sample into the notebook cells.

## UI Deliverables (Today)

- Arena page (Card Deck): two Model Cards (selectable tiles with emoji + short blurb), a 3â€‘pack of Prompt Cards (chips with edit affordance), Run button, outputs sideâ€‘byâ€‘side with mini badges (ms, tokens), Winner selector, â€œShare link,â€ â€œRemix,â€ and â€œRun as Notebook.â€
- Share page: readâ€‘only view of outputs and winner; copy link.
- Share page: readâ€‘only view of outputs, winner, and a Recipe summary (cards rendered as tiles). Primary CTA: â€œRemix this recipe.â€
- Figma: matching flow with simple visual polish, annotated with captions, including Model/Prompt card visuals and a Recipe summary bar.

Card primitives (for this sprint):
- Model Card: title, provider icon (OpenAI/HF), subtitle (e.g., â€œfastâ€/â€œopenâ€), emoji, and selection state.
- Prompt Card: prompt text (single line truncation), emoji, and editable icon to tweak text inline.
- Recipe Bar: compact summary of 2 models + 3 prompts with a fun emoji and title.

## Timeline (Now â†’ +3h)

- 0:00â€“0:20 Setup
  - Create Supabase table; seed one test match; set env vars.
  - Scaffold routes: `/arena`, `/share/[share_id]`, `/api/*`.

- 0:20â€“1:05 Arena â€œhappy pathâ€
  - Hardcode presets; implement `POST /api/match` calling OpenAI and/or HF Inference API.
  - Render Model/Prompt Cards (static tiles); wire selection state to request payload and also serialize into `meta.recipe`.
  - Render sideâ€‘byâ€‘side outputs; compute latencies; allow winner select; save via `/score`.

- 1:05â€“1:50 Notebook generator (HF)
  - Implement `GET /api/notebook` to: fetch HF metadata, fetch README at latest commit, extract snippet, pick pipeline, inject model id, and return `.ipynb`.
  - Verify hello cell locally by constructing payload without sending keys (dry run or static validation).

- 1:50â€“2:20 Share page
  - Implement `GET /api/match/:share_id` + `/share/[share_id]` page.
  - Render Recipe summary and add â€œRemixâ€ CTA linking to `/arena?from={share_id}`.

- 2:20â€“2:45 Figma polish + demo rehearsal
  - Align Figma frames to working UI; add captions; include card visuals and Recipe bar; script the 90â€‘second talk track.

- 2:45â€“3:00 Buffer & failâ€‘safes
  - Add static fallback outputs if APIs fail; preâ€‘generate one share link and one notebook file.

## Risks & Fast Fallbacks

- HF README lacks runnable snippet â†’ fall back to generic `transformers` or Inference API snippet using `pipeline_tag`.
- Inference fails or rateâ€‘limited â†’ serve preâ€‘baked outputs; banner â€œlive inference unavailable; showing cached result.â€
- Supabase write fails â†’ write to local memory (inâ€‘process map) and continue demo; share link maps to memory fallback.
- Time crunch â†’ remove winner voting; just display outputs and a static winner.
 - Card UI too heavy â†’ fall back to dropdowns and textareas, but keep the Recipe summary and Remix link so the concept still demos.

## Success Criteria (Sprint)

- Live demo runs startâ€‘toâ€‘finish without manual data entry.
- One copyâ€‘paste share link loads identical results on a fresh browser.
- Notebook opens and the hello cell returns a completion.
- â€œRemixâ€ from a share page opens Arena with preselected Model/Prompt Cards.

## After Sprint (Next 1â€“2 days)

- Add RLS + simple auth; convert anon writes to userâ€‘scoped writes.
- Add HF Inference adapter and one OSS model preset.
- Add basic evaluator rubric and export of an HTML report.
 - Community Recipes: publish, fork, and remix recipe cards; add lightweight provenance trail (source share_id) to `meta.recipe`.
 - Visual polish: animations for card selection, confetti on winner selection, themed palettes per recipe.

Reference: full product PRD lives at `alacard/alacard-prd.md`.
